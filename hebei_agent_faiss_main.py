from __future__ import annotations
import os
from typing import Dict, List, Tuple, Union
from dotenv import load_dotenv
from openai import OpenAI
from langchain_core.embeddings import Embeddings
from langchain_community.vectorstores import FAISS
from sentence_transformers import SentenceTransformer

# =========================
# 0) é…ç½®DeepSeek Chat
# =========================
load_dotenv()

client = OpenAI(
    api_key=os.getenv("DEEPSEEK_API_KEY"),
    base_url=os.getenv("DEEPSEEK_BASE_URL"),
)
CHAT_MODEL = os.getenv("DEEPSEEK_CHAT_MODEL", "deepseek-chat")

FAISS_DIR = os.getenv("FAISS_DIR", "faiss_hebei")

# =========================
# 0.1) UniAPI
# =========================
UNIAPI_KEY = os.getenv("UNIAPI_KEY")
UNIAPI_BASE = os.getenv("UNIAPI_BASE")
UNIAPI_ENABLED = bool(UNIAPI_KEY and UNIAPI_BASE)

uniapi_client = None
if UNIAPI_ENABLED:
    uniapi_client = OpenAI(api_key=UNIAPI_KEY, base_url=UNIAPI_BASE)

UNIAPI_CHAT_MODEL = os.getenv("UNIAPI_CHAT_MODEL", "gpt-4o-mini")

# =========================
# 1) Embedding
# =========================
class LocalEmbeddings(Embeddings):
    def __init__(self):
        self.model = SentenceTransformer(
            "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
            local_files_only=True
        )

    def embed_documents(self, texts):
        return self.model.encode(texts, show_progress_bar=False).tolist()

    def embed_query(self, text):
        return self.model.encode([text], show_progress_bar=False)[0].tolist()

# =========================
# 2) åŠ è½½ FAISS å‘é‡åº“
# =========================
def load_faiss():
    embeddings = LocalEmbeddings()
    if not os.path.isdir(FAISS_DIR):
        raise FileNotFoundError(
            f"æœªæ‰¾åˆ°å‘é‡åº“ç›®å½• {FAISS_DIR}ï¼Œè¯·å…ˆè¿è¡Œ build_faiss_hebei.py"
        )
    return FAISS.load_local(
        FAISS_DIR,
        embeddings,
        allow_dangerous_deserialization=True
    )


vectorstore = load_faiss()

# =========================
# 3) å…¨å±€çŠ¶æ€ï¼šå¯¹è¯è®°å¿†
# =========================
conversation_memory: Dict[str, List[Tuple[str, str]]] = {}


def get_history_text(user_id: str, last_n: int = 3) -> str:
    history = conversation_memory.get(user_id, [])[-last_n:]
    if not history:
        return "æ— "
    return "\n".join([f"ç”¨æˆ·ï¼š{q}\næ™ºèƒ½ä½“ï¼š{a}" for q, a in history])

# =========================
# 4) FAISS è¯­ä¹‰æ£€ç´¢
# =========================
def retrieve_relevant_knowledge(
    query: str,
    user_id: str,
    top_k: int = 5,
    return_evidence: bool = False
) -> Union[str, Tuple[str, List[dict]]]:
    """
    ä½¿ç”¨ FAISS + æœ¬åœ° embedding è¿›è¡Œè¯­ä¹‰æ£€ç´¢
    - é»˜è®¤è¿”å›æ‹¼æ¥åçš„çŸ¥è¯†å†…å®¹ï¼ˆå­—ç¬¦ä¸²ï¼‰
    - return_evidence=True æ—¶ï¼ŒåŒæ—¶è¿”å› Top-K å‘½ä¸­è¯æ®ï¼ˆtitleç­‰ï¼‰
    """
    history_text = get_history_text(user_id)
    enhanced_query = f"{query}\nï¼ˆå†å²å¯¹è¯ï¼š{history_text}ï¼‰"

    raw_results = vectorstore.similarity_search(enhanced_query, k=top_k * 3)
    if not raw_results:
        if return_evidence:
            return "æ— ç›¸å…³ä¿¡æ¯", []
        return "æ— ç›¸å…³ä¿¡æ¯"

    filtered = []
    for doc in raw_results:
        title = doc.metadata.get("title", "")
        if title.startswith("åŸå¸‚"):
            continue
        filtered.append(doc)
        if len(filtered) >= top_k:
            break

    final_results = filtered if filtered else raw_results[:top_k]

    evidence = []
    for doc in final_results:
        evidence.append({
            "title": doc.metadata.get("title", doc.metadata.get("name", "æœªå‘½å")),
            "type": doc.metadata.get("type", ""),
            "city": doc.metadata.get("city", ""),
            "name": doc.metadata.get("name", ""),
            "id": doc.metadata.get("id", None),
        })

    print("\nã€å‘é‡æ£€ç´¢å‘½ä¸­ Top-K æ¡ç›®ï¼ˆè¿‡æ»¤åï¼‰ã€‘")
    for i, e in enumerate(evidence, 1):
        print(f"[å‘½ä¸­{i}] {e.get('title')}")
    print("================================\n")

    merged_text = "\n\n".join([doc.page_content for doc in final_results])

    if return_evidence:
        return merged_text, evidence
    return merged_text

# =========================
# 4.1) UniAPI è¯­è¨€å¢å¼º
# =========================
def enhance_with_uniapi(answer: str, user_query: str) -> str:
    """
    æ³¨æ„ï¼šåªåšè¡¨è¾¾å¢å¼ºï¼Œä¸å¼•å…¥æ–°ä¿¡æ¯ã€ä¸æ–°å¢äº‹å®ã€‚
    UniAPI å¤±è´¥æ—¶è‡ªåŠ¨å›é€€ä¸ºåŸå§‹å›ç­”ã€‚
    """
    if not UNIAPI_ENABLED or not uniapi_client:
        return answer

    prompt = f"""
ä½ æ˜¯æ—…æ¸¸äº§å“çš„â€œæ–‡æ¡ˆæ¶¦è‰²åŠ©æ‰‹â€ã€‚è¯·å¯¹ä¸‹é¢ã€åŸå§‹å›ç­”ã€‘è¿›è¡Œä¼˜åŒ–ï¼Œä½¿å…¶æ›´åƒå•†ä¸šäº§å“çš„è¾“å‡ºï¼š
- ä¿ç•™åŸå§‹äº‹å®
- ç»“æ„æ›´æ¸…æ™°ï¼šç”¨å°æ ‡é¢˜ + åˆ†ç‚¹
- æ›´â€œä¿å§†çº§â€ï¼šç»™å‡ºæ“ä½œæ­¥éª¤ã€æ³¨æ„äº‹é¡¹ã€èŠ‚å¥å»ºè®®
- è¯­è¨€æ›´è‡ªç„¶æ›´å¸å¼•äººï¼Œä½†ä¸å¤¸å¼ 

ç”¨æˆ·é—®é¢˜ï¼š
{user_query}

åŸå§‹å›ç­”ï¼ˆäº‹å®æ¥æºäºçŸ¥è¯†åº“ï¼‰ï¼š
{answer}

åªè¾“å‡ºæ¶¦è‰²åçš„æœ€ç»ˆå›ç­”æ­£æ–‡ï¼Œä¸è¦è§£é‡Šã€‚
""".strip()

    try:
        resp = uniapi_client.chat.completions.create(
            model=UNIAPI_CHAT_MODEL,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2,
            max_tokens=900
        )
        return resp.choices[0].message.content.strip()

    except Exception as e:
        print("[UniAPI å¢å¼ºå¤±è´¥ï¼Œå·²å›é€€ä¸ºæœ¬åœ°å›ç­”]")
        print("åŸå› ï¼š", e)
        return answer

# =========================
# 5) æ ¸å¿ƒé—®ç­”å‡½æ•°
# =========================
def get_hebei_answer(
    user_query: str,
    user_id: str = "default",
    use_llm_enhance: bool = False,
    return_evidence: bool = False
) -> Union[str, Tuple[str, List[dict]]]:
    """
    - use_llm_enhance: True æ—¶å¯ç”¨ UniAPI è¡¨è¾¾å¢å¼ºï¼ˆä»…æ¶¦è‰²ï¼‰
    - return_evidence: True æ—¶è¿”å› (answer, evidence)
    """
    user_query = user_query.strip()
    if not user_query:
        msg = "ğŸ˜¯ ä½ è¿˜æ²¡è¾“å…¥é—®é¢˜å“¦ï¼å¯ä»¥é—®æ¯”å¦‚â€œæ‰¿å¾·é¿æš‘å±±åº„é—¨ç¥¨â€â€œä¿å®šé©´è‚‰ç«çƒ§å“ªå®¶æ­£å®—â€ï½"
        return (msg, []) if return_evidence else msg

    too_vague = ["æ²³åŒ—æ—…æ¸¸", "æ²³åŒ—å¥½ç©å—", "æ¨èä»€ä¹ˆ", "æ€ä¹ˆç©", "æœ‰å•¥å¥½ç©çš„"]
    if any(word == user_query for word in too_vague):
        msg = (
            "ğŸ’¡ ä½ å¯ä»¥å…·ä½“é—®è¿™äº›å“¦ï¼š\n"
            "1. æ™¯ç‚¹ç±»ï¼šXXæ™¯ç‚¹é—¨ç¥¨ / å¼€æ”¾æ—¶é—´ / æ€ä¹ˆå»\n"
            "2. ç¾é£Ÿç±»ï¼šXXåŸå¸‚ç‰¹è‰²ç¾é£Ÿ / æ¨èåº—é“º\n"
            "3. è¡Œç¨‹ç±»ï¼šæ²³åŒ—Xæ—¥æ¸¸ï¼ˆäº²å­ / è€äºº / æƒ…ä¾£ï¼‰\n"
            "4. å®ç”¨ç±»ï¼šé¢„çº¦æ–¹å¼ / é¿å‘æŒ‡å— / äº¤é€šæ”»ç•¥"
        )
        return (msg, []) if return_evidence else msg

    # === FAISS æ£€ç´¢ ===
    if return_evidence:
        relevant_knowledge, evidence = retrieve_relevant_knowledge(
            user_query, user_id=user_id, top_k=5, return_evidence=True
        )
    else:
        relevant_knowledge = retrieve_relevant_knowledge(
            user_query, user_id=user_id, top_k=5, return_evidence=False
        )
        evidence = []

    if relevant_knowledge == "æ— ç›¸å…³ä¿¡æ¯":
        msg = "ğŸ˜… æŠ±æ­‰ï¼Œæˆ‘çš„çŸ¥è¯†åº“é‡Œæš‚æ—¶æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œå¯ä»¥æ¢ä¸ªé—®æ³•è¯•è¯•ï½"
        return (msg, evidence) if return_evidence else msg

    # === å›ç­”ç”Ÿæˆ ===
    history_text = get_history_text(user_id)

    final_prompt = f"""
ä½ æ˜¯ä¸€ä¸ªã€æ—…æ¸¸äº§å“çº§è¡Œç¨‹è§„åˆ’å¼•æ“ã€‘ï¼Œä¸æ˜¯èŠå¤©æœºå™¨äººã€‚

è¯·æ ¹æ®ã€çŸ¥è¯†åº“å†…å®¹ã€‘ï¼Œä¸ºç”¨æˆ·ç”Ÿæˆä¸€ä»½ã€å¯ç›´æ¥æ‰§è¡Œçš„æ²³åŒ—æ—…æ¸¸è¡Œç¨‹æ–¹æ¡ˆã€‘ï¼Œå¿…é¡»æ»¡è¶³ä»¥ä¸‹è¦æ±‚ï¼š

ã€ä¸€ã€æ•´ä½“è¦æ±‚ï¼ˆéå¸¸é‡è¦ï¼‰ã€‘
- è¾“å‡ºçš„æ˜¯â€œæœ€ç»ˆå¯ç”¨æ–¹æ¡ˆâ€ï¼Œä¸æ˜¯å»ºè®®è‰ç¨¿
- ä¸è¦æç¤ºç”¨æˆ·â€œå¯ä»¥è¡¥å……â€â€œå¯å†æŸ¥è¯¢â€â€œå»ºè®®è¿›ä¸€æ­¥äº†è§£â€
- ä¸è¦æŠŠä»»ä½•å·¥ä½œäº¤ç»™ç”¨æˆ·
- å‡è®¾ç”¨æˆ·ä¼šä¸¥æ ¼ç…§ç€ä½ ç»™çš„å†…å®¹å‡ºè¡Œ

ã€äºŒã€ç»“æ„è¦æ±‚ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰ã€‘
- æŒ‰å¤©è¾“å‡ºï¼ˆDay 1 / Day 2 / Day 3 â€¦ï¼‰
- æ¯ä¸€å¤©éƒ½å¿…é¡»åŒ…å«ä»¥ä¸‹å››ä¸ªæ¨¡å—ï¼ˆç¼ºä¸€ä¸å¯ï¼‰ï¼š

1ï¸âƒ£ ä»Šæ—¥è¡Œç¨‹æ¦‚è§ˆ  
   - åŸå¸‚ / åŒºåŸŸ  
   - ä¸»è¦æ¸¸è§ˆæ™¯ç‚¹ï¼ˆæŒ‰é¡ºåºï¼‰

2ï¸âƒ£ ğŸŸ é—¨ç¥¨ä¸å¿…è¦æ¶ˆè´¹  
   - æ˜ç¡®åˆ—å‡ºå½“å¤©æ¶‰åŠæ™¯ç‚¹çš„é—¨ç¥¨ä»·æ ¼  
   - è‹¥æœ‰è§‚å…‰è½¦ / æ¸¸èˆ¹ / äºŒæ¬¡æ¶ˆè´¹ï¼Œéœ€ä¸€å¹¶åˆ—å‡º  
   - ç”¨â€œçº¦ / äººæ°‘å¸â€æ ‡æ³¨ï¼Œä¿æŒåŠ¡å®

3ï¸âƒ£ ğŸš— äº¤é€šä¸ç§»åŠ¨æ–¹å¼  
   - åŸå¸‚é—´æˆ–æ™¯ç‚¹é—´äº¤é€šæ–¹å¼ï¼ˆé«˜é“ / å¤§å·´ / è‡ªé©¾ / å¸‚å†…å…¬äº¤ï¼‰  
   - ç»™å‡ºå¯æ‰§è¡Œçš„æ–¹æ¡ˆï¼ˆå¦‚ï¼šé«˜é“ + å¸‚å†…æ‰“è½¦ï¼‰  
   - è¯´æ˜å¤§è‡´æ—¶é—´æˆæœ¬æˆ–è´¹ç”¨åŒºé—´

4ï¸âƒ£ âš ï¸ å½“å¤©æ‰§è¡Œæé†’ï¼ˆäº§å“çº§ï¼‰  
   - æ’é˜Ÿ / é™æµ / é¢„çº¦  
   - è€äºº / äº²å­ / å­¦ç”Ÿæ³¨æ„äº‹é¡¹  
   - æ—¶é—´å®‰æ’èŠ‚å¥ï¼ˆä¸Šåˆ / ä¸‹åˆ / æ™šä¸Šï¼‰

ã€ä¸‰ã€å†…å®¹æ¥æºçº¦æŸã€‘
- æ‰€æœ‰äº‹å®ï¼ˆé—¨ç¥¨ã€äº¤é€šã€å¼€æ”¾æ—¶é—´ï¼‰å¿…é¡»æ¥è‡ªã€çŸ¥è¯†åº“å†…å®¹ã€‘
- ç¦æ­¢ç¼–é€ ã€ä¸ç¡®å®šä¿¡æ¯å¯ç”¨â€œä»¥æ™¯åŒºå®˜æ–¹ä¸ºå‡†â€è¡¨è¿°
- è‹¥çŸ¥è¯†åº“ä¸­ä¿¡æ¯ä¸è¶³ï¼Œéœ€ç”¨â€œä¿å®ˆæ–¹æ¡ˆâ€è€Œä¸æ˜¯ç•™ç©º

ã€å››ã€è¯­è¨€é£æ ¼ã€‘
- å•†ä¸šäº§å“è¯´æ˜ä¹¦é£æ ¼
- æ¸…æ™°ã€æœ‰æ¡ç†ã€åâ€œä¿å§†çº§â€
- ä¸å¤¸å¼ ã€ä¸è¥é”€ã€ä¸å£æ°´

ã€äº”ã€ç»“å°¾è¦æ±‚ã€‘
- ä¸è¦æé—®ç”¨æˆ·
- ä¸è¦è®©ç”¨æˆ·ç»§ç»­è¡¥å……
- ç»“å°¾åªå…è®¸ä¸€å¥æ€»ç»“æ€§è¯´æ˜ï¼Œä¾‹å¦‚ï¼š
  â€œä»¥ä¸Šè¡Œç¨‹å·²è¡¥é½é—¨ç¥¨ä¸äº¤é€šä¿¡æ¯ï¼Œå¯ç›´æ¥ä½œä¸ºå‡ºè¡Œè®¡åˆ’ä½¿ç”¨ã€‚â€

ã€çŸ¥è¯†åº“å†…å®¹å¦‚ä¸‹ã€‘
{{relevant_knowledge}}

ã€ç”¨æˆ·éœ€æ±‚ã€‘
{{user_query}}

è¯·ç›´æ¥è¾“å‡ºæœ€ç»ˆè¡Œç¨‹æ­£æ–‡ã€‚

""".strip()

    response = client.chat.completions.create(
        model=CHAT_MODEL,
        messages=[{"role": "user", "content": final_prompt}],
        temperature=0.2,
        max_tokens=900,
    )
    answer = response.choices[0].message.content.strip()

    if use_llm_enhance:
        answer = enhance_with_uniapi(answer=answer, user_query=user_query)

    conversation_memory.setdefault(user_id, [])
    conversation_memory[user_id].append((user_query, answer))
    conversation_memory[user_id] = conversation_memory[user_id][-3:]

    return (answer, evidence) if return_evidence else answer


# =========================
# 6) CLI å…¥å£
# =========================
if __name__ == "__main__":
    print("ğŸ‰ æ²³åŒ—æ—…æ¸¸æ™ºèƒ½ä½“å¯åŠ¨ï¼")
    print("ğŸ’¡ è¿™ä¹ˆè¿‘ï¼Œé‚£ä¹ˆç¾ï¼Œå‘¨æœ«åˆ°æ²³åŒ—~~\n")

    USER_ID = "hebei_travel_user_001"

    while True:
        user_input = input("ä½ ï¼š").strip()
        if user_input.lower() in ["æ‹œæ‹œ", "é€€å‡º", "ç»“æŸ"]:
            print("æ™ºèƒ½ä½“ï¼šç¥ä½ åœ¨æ²³åŒ—ç©å¾—å¼€å¿ƒï¼ğŸ‘‹")
            conversation_memory.pop(USER_ID, None)
            break

        ans = get_hebei_answer(user_input, USER_ID, use_llm_enhance=False)
        print(f"æ™ºèƒ½ä½“ï¼š{ans}\n")
